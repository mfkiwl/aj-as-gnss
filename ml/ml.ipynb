{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'D:/dataset'\n",
    "x_t_path  = DATASET_PATH + '/x_t'\n",
    "r_t_path = DATASET_PATH + '/r_t'\n",
    "r_s_path = DATASET_PATH + '/r_s'\n",
    "a_authentic_path = DATASET_PATH + '/amplitudes_authentic'\n",
    "doa_authentic_path = DATASET_PATH + '/doa_authentic'\n",
    "doa_jamming_path = DATASET_PATH + '/doa_jamming'\n",
    "doa_spoofed_path = DATASET_PATH + '/doa_spoofed'\n",
    "NUM_SAMPLES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the authentic, spoofed and jammed signals from r_t\n",
    "def get_r_t():\n",
    "    r_t = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = r_t_path + '/' + str(i) + '.mat'\n",
    "        r_t.append(scipy.io.loadmat(SAMPLE_PATH)['r_t'])\n",
    "    return r_t\n",
    "\n",
    "# get the original signals from x_t\n",
    "def get_x_t():\n",
    "    x_t = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = x_t_path + '/' + str(i) + '.mat'\n",
    "        x_t.append(scipy.io.loadmat(SAMPLE_PATH)['x_t'])\n",
    "    return x_t\n",
    "\n",
    "# get the doa_spoofed\n",
    "def get_doa_spoofed():\n",
    "    doa_spoofed = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = doa_spoofed_path + '/' + str(i) + '.mat'\n",
    "        doa_spoofed.append(scipy.io.loadmat(SAMPLE_PATH)['doa_spoofed'])\n",
    "    return doa_spoofed\n",
    "\n",
    "# get the doa_jamming\n",
    "def get_doa_jamming():\n",
    "    doa_jamming = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = doa_jamming_path + '/' + str(i) + '.mat'\n",
    "        doa_jamming.append(scipy.io.loadmat(SAMPLE_PATH)['doa_jamming'])\n",
    "    return doa_jamming\n",
    "\n",
    "# get the doa_authentic\n",
    "def get_doa_authentic():\n",
    "    doa_authentic = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = doa_authentic_path + '/' + str(i) + '.mat'\n",
    "        doa_authentic.append(scipy.io.loadmat(SAMPLE_PATH)['doa_authentic'])\n",
    "    return doa_authentic\n",
    "\n",
    "# get the amplitudes_authentic\n",
    "def get_amplitudes_authentic():\n",
    "    amplitudes_authentic = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = a_authentic_path + '/' + str(i) + '.mat'\n",
    "        amplitudes_authentic.append(scipy.io.loadmat(SAMPLE_PATH)['amplitudes_authentic'])\n",
    "    return amplitudes_authentic\n",
    "\n",
    "# get the r_s\n",
    "def get_r_s():\n",
    "    r_s = []\n",
    "    for i in range(1, NUM_SAMPLES+1):\n",
    "        SAMPLE_PATH = r_s_path + '/' + str(i) + '.mat'\n",
    "        r_s.append(scipy.io.loadmat(SAMPLE_PATH)['r_s'])\n",
    "    return r_s\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    r_t = get_r_t()\n",
    "    # x_t = get_x_t()\n",
    "    doa_spoofed = get_doa_spoofed()\n",
    "    doa_jamming = get_doa_jamming()\n",
    "    doa_authentic = get_doa_authentic()\n",
    "    amplitudes_authentic = get_amplitudes_authentic()\n",
    "    # r_s = get_r_s()\n",
    "    return r_t, doa_spoofed, doa_jamming, doa_authentic, amplitudes_authentic\n",
    "\n",
    "# split the data into training and testing\n",
    "def split_data(r_t, y):\n",
    "    x_train, x_test = r_t[:200], r_t[200:]\n",
    "    y_train, y_test = y[:200], y[200:]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 38363)\n",
      "(1, 4)\n",
      "(1, 1)\n",
      "(1, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "r_t, doa_spoofed, doa_jamming, doa_authentic, amplitudes_authentic = get_data()\n",
    "print(r_t[0].shape)\n",
    "print(doa_spoofed[0].shape)\n",
    "print(doa_jamming[0].shape)\n",
    "print(doa_authentic[0].shape)\n",
    "print(amplitudes_authentic[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "(1, 13)\n"
     ]
    }
   ],
   "source": [
    "# combine doa_spoofed, doa_jamming, doa_authentic, amplitudes_authentic into one array\n",
    "y = []\n",
    "for i in range(NUM_SAMPLES):\n",
    "    y.append(np.concatenate((doa_spoofed[i], doa_jamming[i], doa_authentic[i], amplitudes_authentic[i]), axis=1))\n",
    "print(len(y))\n",
    "print(y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "x_train, x_test, y_train, y_test = split_data(r_t, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a CNN model that takes in the r_t and y_train include dropout and batch normalization layers\n",
    "# \n",
    "# each r_t is of shape (10, 38363)\n",
    "# each y_train is of shape (13, 1)\n",
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv1D(32, 3, activation='relu', input_shape=x_train[0].shape, data_format='channels_first'))\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Conv1D(64, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Conv1D(128, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Conv1D(256, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(y_train[0].shape[0], activation='softmax'))\n",
    "    # optimiser rmsprop\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a MLP model that takes in the r_t and y_train\n",
    "# each r_t is of shape (10, 38363)\n",
    "# each y_train is of shape (13,)\n",
    "def get_mlp_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(10, 38363)))\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(13, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[383630,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mlp_model \u001b[39m=\u001b[39m get_mlp_model()\n\u001b[0;32m      2\u001b[0m mlp_model\u001b[39m.\u001b[39mfit(x_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[89], line 7\u001b[0m, in \u001b[0;36mget_mlp_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential()\n\u001b[0;32m      6\u001b[0m model\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(input_shape\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m38363\u001b[39m)))\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39;49madd(keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m512\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m13\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[0;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[0;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[0;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   2106\u001b[0m     )\n\u001b[0;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[383630,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "mlp_model = get_mlp_model()\n",
    "mlp_model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 38363)\n",
      "(13,)\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.14 GiB for an array with shape (200, 10, 38363) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(y_train))\n\u001b[0;32m      6\u001b[0m \u001b[39m# reshape x_train and y_train to have the same shape\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m x_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(x_train, (\u001b[39m200\u001b[39;49m, \u001b[39m383630\u001b[39;49m))\n\u001b[0;32m      8\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(y_train, (\u001b[39m200\u001b[39m, \u001b[39m13\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.14 GiB for an array with shape (200, 10, 38363) and data type complex128"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "print(y_train[0].shape)\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "\n",
    "# reshape x_train and y_train to have the same shape\n",
    "x_train = np.reshape(x_train, (200, 383630))\n",
    "y_train = np.reshape(y_train, (200, 13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_70 (Conv1D)          (None, 32, 38361)         992       \n",
      "                                                                 \n",
      " max_pooling1d_60 (MaxPoolin  (None, 16, 38361)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 14, 64)            7365376   \n",
      "                                                                 \n",
      " max_pooling1d_61 (MaxPoolin  (None, 7, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_72 (Conv1D)          (None, 5, 128)            24704     \n",
      "                                                                 \n",
      " max_pooling1d_62 (MaxPoolin  (None, 2, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 13)                6669      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,529,325\n",
      "Trainable params: 7,529,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.14 GiB for an array with shape (200, 10, 38363) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39mfit(np\u001b[39m.\u001b[39;49masarray(x_train), np\u001b[39m.\u001b[39masarray(y_train), epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.14 GiB for an array with shape (200, 10, 38363) and data type complex128"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "print(model.summary())\n",
    "model.fit(np.asarray(x_train), np.asarray(y_train), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
